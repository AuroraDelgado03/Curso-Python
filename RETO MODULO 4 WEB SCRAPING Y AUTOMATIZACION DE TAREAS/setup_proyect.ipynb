{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40554808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos trabajando en: c:\\Users\\LENOVO\\Documents\\MEGA CURSO PYTHON\\CURSO WEB SCRAPING Y AUTOMATIZACION DE TAREAS\n",
      "\n",
      "Ruta construida: c:\\Users\\LENOVO\\Documents\\MEGA CURSO PYTHON\\CURSO WEB SCRAPING Y AUTOMATIZACION DE TAREAS\\Proyecto_Scraping\n",
      "La carpeta c:\\Users\\LENOVO\\Documents\\MEGA CURSO PYTHON\\CURSO WEB SCRAPING Y AUTOMATIZACION DE TAREAS\\Proyecto_Scraping\\data_raw fue creada con éxito\n",
      "La carpeta c:\\Users\\LENOVO\\Documents\\MEGA CURSO PYTHON\\CURSO WEB SCRAPING Y AUTOMATIZACION DE TAREAS\\Proyecto_Scraping\\data_clean fue creada con éxito\n",
      "La carpeta c:\\Users\\LENOVO\\Documents\\MEGA CURSO PYTHON\\CURSO WEB SCRAPING Y AUTOMATIZACION DE TAREAS\\Proyecto_Scraping\\img fue creada con éxito\n",
      "La carpeta c:\\Users\\LENOVO\\Documents\\MEGA CURSO PYTHON\\CURSO WEB SCRAPING Y AUTOMATIZACION DE TAREAS\\Proyecto_Scraping\\logs fue creada con éxito\n",
      "El archivo fue creado con éxito\n"
     ]
    }
   ],
   "source": [
    "# --- RETO 1 ---\n",
    "\n",
    "# --- Importar ---\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "nombre_proyecto = \"Proyecto_Scraping\" \n",
    "\n",
    "# Obtener el directorio actual de trabajo (Current Working Directory)\n",
    "base_dir = Path.cwd()\n",
    "print(f\"Estamos trabajando en: {base_dir}\")\n",
    "\n",
    "# Crear la ruta en memoria\n",
    "carpeta_datos = base_dir / nombre_proyecto\n",
    "print(f\"\\nRuta construida: {carpeta_datos}\")\n",
    "\n",
    "# Crear la ruta de las carpetas\n",
    "carpetas_a_crear = [\n",
    "    carpeta_datos / \"data_raw\",\n",
    "    carpeta_datos / \"data_clean\",\n",
    "    carpeta_datos / \"img\",\n",
    "    carpeta_datos / \"logs\",\n",
    "]\n",
    "\n",
    "# Crear la función para crear las carpetas\n",
    "def crear_carpetas(lista_carpetas):\n",
    "    \"\"\"\n",
    "    Función auxiliar para crear las carpetas en la ruta específicada\n",
    "    \"\"\"\n",
    "    # 1. Crear la carpeta física si no existe\n",
    "    # parents=True crea carpetas intermedias si faltan\n",
    "    # exist_ok=True evita errores si la carpeta ya existe\n",
    "    for carpetas in lista_carpetas:\n",
    "        carpetas.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"La carpeta {carpetas} fue creada con éxito\")\n",
    "\n",
    "crear_carpetas(carpetas_a_crear)\n",
    "\n",
    "#  EXTRA: Crear el archivo readme.txt\n",
    "def create_readme(logs_folder):\n",
    "    \"\"\"\n",
    "    Función auxiliar para crear el archivo \"readme.txt\"\n",
    "    \"\"\"\n",
    "    readme_path = logs_folder / \"readme.txt\"\n",
    "    print(f\"El archivo fue creado con éxito\")\n",
    "\n",
    "    # Solo lo creamos si NO existe (idempotencia)\n",
    "    if not readme_path.exists():\n",
    "        fecha = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        texto = f\"Este proyecto fue inicializado el {fecha}\\n\"\n",
    "        readme_path.write_text(texto)\n",
    "\n",
    "create_readme(carpeta_datos / \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d2a75d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Conexión exitosa con el servidor.\n",
      "Archivo crudo guardado en: c:\\Users\\LENOVO\\Documents\\MEGA CURSO PYTHON\\CURSO WEB SCRAPING Y AUTOMATIZACION DE TAREAS\\Proyecto_Scraping\\data_raw\\raw_mystery_3.html\n",
      "\n",
      "--- Muestra de datos extraídos (20 total) ---\n",
      "{'titulo': 'Sharp Objects', 'precio': 47.82, 'rating': 'Four'}\n",
      "{'titulo': 'In a Dark, Dark Wood', 'precio': 19.63, 'rating': 'One'}\n",
      "{'titulo': 'The Past Never Ends', 'precio': 56.5, 'rating': 'Four'}\n",
      "{'titulo': 'A Murder in Time', 'precio': 16.64, 'rating': 'One'}\n",
      "{'titulo': 'The Murder of Roger Ackroyd (Hercule Poirot #4)', 'precio': 44.1, 'rating': 'Four'}\n",
      "\n",
      "✅ Conexión exitosa con el servidor.\n",
      "Archivo crudo guardado en: c:\\Users\\LENOVO\\Documents\\MEGA CURSO PYTHON\\CURSO WEB SCRAPING Y AUTOMATIZACION DE TAREAS\\Proyecto_Scraping\\data_raw\\raw_science-fiction_16.html\n",
      "\n",
      "--- Muestra de datos extraídos (16 total) ---\n",
      "{'titulo': 'Mesaerion: The Best Science Fiction Stories 1800-1849', 'precio': 37.59, 'rating': 'One'}\n",
      "{'titulo': 'Join', 'precio': 35.67, 'rating': 'Five'}\n",
      "{'titulo': \"William Shakespeare's Star Wars: Verily, A New Hope (William Shakespeare's Star Wars #4)\", 'precio': 43.3, 'rating': 'Four'}\n",
      "{'titulo': 'The Project', 'precio': 10.65, 'rating': 'One'}\n",
      "{'titulo': 'Soft Apocalypse', 'precio': 26.12, 'rating': 'Two'}\n",
      "\n",
      "Resultados: \n",
      "Mystery: 20 libros\n",
      "Science Fiction: 16 libros\n"
     ]
    }
   ],
   "source": [
    "# --- RETO 2 ---\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importamos la librería de expresiones regulares\n",
    "\n",
    "def analizar_categoria(url_categoria):\n",
    "    # Usar un \"User-Agent\" para disfrazarnos de navegador.\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Realizar la petición GET\n",
    "    response = requests.get(url_categoria, headers=headers)\n",
    "\n",
    "    # Verificar el estado (Status Code)\n",
    "    # 200 = Éxito, 404 = No encontrado, 403 = Prohibido, 500 = Error del servidor\n",
    "    if response.status_code == 200:\n",
    "        print(\"\\n✅ Conexión exitosa con el servidor.\")\n",
    "        html_content = response.text\n",
    "    else:\n",
    "        print(f\"❌ Error en la conexión: {response.status_code}\")\n",
    "\n",
    "    # Crear carpeta si no existe y guardar\n",
    "    ruta_raw = carpeta_datos / \"data_raw\"\n",
    "    ruta_raw.mkdir(exist_ok=True) # Por seguridad\n",
    "\n",
    "    titulo_categoria = url_categoria.split('/')[-2] # EXTRA: obtener el nombre de la categoría desde la URL automáticamente\n",
    "    nombre_archivo = f\"raw_{titulo_categoria}.html\"\n",
    "    ruta_completa = ruta_raw / nombre_archivo\n",
    "\n",
    "    # Guardamos el HTML tal cual (encoding='utf-8' es vital para tildes y símbolos)\n",
    "    with open(ruta_completa, 'w', encoding='utf-8') as f:\n",
    "        f.write(response.text)\n",
    "    print(f\"Archivo crudo guardado en: {ruta_completa}\")\n",
    "\n",
    "    # Crear el objeto \"Sopa\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    libros_containers = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "    datos_libros = []\n",
    "\n",
    "    for libro in libros_containers:\n",
    "        try:\n",
    "            # --- Extracción del Título ---\n",
    "            titulo = libro.h3.a['title']\n",
    "            \n",
    "            # --- Extracción del Precio (Método Robusto) ---\n",
    "            precio_texto = libro.find('p', class_='price_color').text\n",
    "            \n",
    "            # Usamos Regex para buscar solo números y puntos\n",
    "            # Patrón r\"[\\d\\.]+\" significa: \"Encuentra dígitos (0-9) o puntos (.) uno o más veces\"\n",
    "            match = re.search(r\"[\\d\\.]+\", precio_texto)\n",
    "            \n",
    "            if match:\n",
    "                # Si encuentra números, tomamos solo esa parte y convertimos\n",
    "                precio_numerico = float(match.group())\n",
    "            else:\n",
    "                # Si por alguna razón no hay precio, ponemos 0.0 o NaN\n",
    "                precio_numerico = 0.0\n",
    "            \n",
    "            # --- Extracción de Estrellas (Rating) ---\n",
    "            clases_rating = libro.find('p', class_='star-rating')['class']\n",
    "            rating = clases_rating[1] if len(clases_rating) > 1 else \"Not Rated\"\n",
    "            \n",
    "            # Guardamos en diccionario\n",
    "            datos_libros.append({\n",
    "                \"titulo\": titulo,\n",
    "                \"precio\": precio_numerico,\n",
    "                \"rating\": rating\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parseando un libro: {e}\")\n",
    "\n",
    "    # Verificamos los resultados\n",
    "    print(f\"\\n--- Muestra de datos extraídos ({len(datos_libros)} total) ---\")\n",
    "    for l in datos_libros[:5]:\n",
    "        print(l)\n",
    "    return datos_libros\n",
    "\n",
    "# URL objetivo\n",
    "url_mystery = \"http://books.toscrape.com/catalogue/category/books/mystery_3/index.html\"\n",
    "url_scifi = \"http://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html\"\n",
    "\n",
    "libros_mystery = analizar_categoria(url_mystery)\n",
    "libros_scifi   = analizar_categoria(url_scifi)\n",
    "\n",
    "print(\"\\nResultados: \")\n",
    "print(f\"Mystery: {len(libros_mystery)} libros\")\n",
    "print(f\"Science Fiction: {len(libros_scifi)} libros\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
